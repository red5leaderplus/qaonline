import streamlit as st
import pandas as pd
import jieba
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel

# default page configuration on main block
st.set_page_config(page_title="ä¸­æ–‡å®¢æœæª¢ç´¢å›è¦†", page_icon="ğŸ’¬", layout="wide")
st.title('ä¸­æ–‡å®¢æœæª¢ç´¢æœå‹™')

q = st.text_input("è«‹è¼¸å…¥å•é¡Œ(ä¸­æ–‡)",placeholder="ä¾‹å¦‚:å¦‚ä½•é€€è²¨?")
query = st.button("é€å‡º")
result_placeholder = st.empty()
st.markdown('---')
if "status_label" not in st.session_state:
    st.session_state.status_label = "ç‹€æ…‹ï¼šåˆå§‹åŒ–Q&Aè³‡æ–™åº«"
if "status_state" not in st.session_state:
    st.session_state.status_state = "running"
status_box = st.status(st.session_state.status_label, state=st.session_state.status_state)

DEFAULT_FAQ = pd.DataFrame(
    [
        {"question":"ä½ å€‘çš„ç‡Ÿæ¥­æ™‚é–“æ˜¯ï¼Ÿ","answer":"æˆ‘å€‘çš„å®¢æœæ™‚é–“ç‚ºé€±ä¸€è‡³é€±äº” 09:00â€“18:00ï¼ˆåœ‹å®šå‡æ—¥é™¤å¤–ï¼‰ã€‚"},
        {"question":"å¦‚ä½•ç”³è«‹é€€è²¨ï¼Ÿ","answer":"è«‹æ–¼åˆ°è²¨ 7 å¤©å…§é€éè¨‚å–®é é¢é»é¸ã€ç”³è«‹é€€è²¨ã€ï¼Œç³»çµ±å°‡å¼•å°æ‚¨å®Œæˆæµç¨‹ã€‚"},
        {"question":"é‹è²»å¦‚ä½•è¨ˆç®—ï¼Ÿ","answer":"å–®ç­†è¨‚å–®æ»¿ NT$ 1000 å…é‹ï¼Œæœªæ»¿å‰‡é…Œæ”¶ NT$ 80ã€‚"},
        {"question":"å¯ä»¥é–‹ç«‹ç™¼ç¥¨å—ï¼Ÿ","answer":"æˆ‘å€‘æä¾›é›»å­ç™¼ç¥¨ï¼Œè«‹æ–¼çµå¸³æ™‚å¡«å¯«çµ±ä¸€ç·¨è™Ÿèˆ‡æŠ¬é ­ã€‚"},
    ]
)

if "faq_df" not in st.session_state:
    st.session_state.faq_df = DEFAULT_FAQ.copy()
if "vectorizer" not in st.session_state:
    st.session_state.vectorizer = None
if "tfidf" not in st.session_state:
    st.session_state.tfidf = None

with st.expander('æª¢è¦–ç¾æœ‰Q&Aè³‡æ–™', expanded=False):
    st.dataframe(st.session_state.faq_df, use_container_width=True)

# Sidebar for knowledge base operations
with st.sidebar:
    st.header("çŸ¥è­˜åº«æ“ä½œ")
    uploader = st.file_uploader('é™ä¸Šå‚³CSVæª”', type=['csv'])
    if uploader is not None:
        df = pd.read_csv(uploader)
        st.session_state.faq_df = df.dropna().reset_index(drop=True)
        st.success(f'å·²æˆåŠŸè¼‰å…¥{len(df)}ç­†è³‡æ–™ã€‚')
    do_index = st.button("æ›´æ–°Q&Aç´¢å¼•")
    st.markdown("---")
    st.header("åƒæ•¸è¨­ç½®")
    top_k = st.slider("å–å¾—å‰kç­†å›ç­”", 1, 3, value=2, key="top_k_slider")
    c = st.slider("ä¿¡å¿ƒé–€æª»", 0.0, 1.0, value=0.3, key="confidence_slider")

# Function to tokenize text using jieba
def jieba_tokenize(text:str):
    return list(jieba.cut(text))#å°‡å¥å­åˆ†è©

if st.session_state.vectorizer is None:
    st.session_state.status_label = "ç‹€æ…‹ï¼šå°šæœªå»ºç«‹ç´¢å¼•ï¼Œæœƒè‡ªå‹•å»ºç«‹"
    st.session_state.status_state = "running"
    status_box.update(label=st.session_state.status_label, state=st.session_state.status_state)
    corpus = (st.session_state.faq_df["question"].astype(str)+
              " "+
              st.session_state.faq_df["answer"].astype(str)).tolist()
    v = TfidfVectorizer(tokenizer=jieba_tokenize)
    tfidf = v.fit_transform(corpus)
    st.session_state.vectorizer = v
    st.session_state.tfidf = tfidf
    st.session_state.status_label = "ç‹€æ…‹ï¼šå·²æˆåŠŸè¼‰å…¥é è¨­çš„Q&Aè³‡æ–™"
    st.session_state.status_state = "complete"
    status_box.update(label=st.session_state.status_label, state=st.session_state.status_state)
elif do_index:
    corpus = (st.session_state.faq_df["question"].astype(str)+
              " "+
              st.session_state.faq_df["answer"].astype(str)).tolist()
    v = TfidfVectorizer(tokenizer=jieba_tokenize)
    tfidf = v.fit_transform(corpus)
    st.session_state.vectorizer = v
    st.session_state.tfidf = tfidf
    st.session_state.status_label = "ç‹€æ…‹ï¼šå·²æˆåŠŸè¼‰å…¥æ–°ä¸Šå‚³çš„Q&Aè³‡æ–™"
    st.session_state.status_state = "complete"
    status_box.update(label=st.session_state.status_label, state=st.session_state.status_state)

# query processing
if query and q.strip():
    st.session_state.status_label = "æŸ¥è©¢ä¸­..."
    st.session_state.status_state = "running"
    status_box.update(label=st.session_state.status_label, state=st.session_state.status_state)
    corpus = (st.session_state.faq_df["question"].astype(str)+
              " "+
              st.session_state.faq_df["answer"].astype(str)).tolist()
    v = TfidfVectorizer(tokenizer=jieba_tokenize)
    tfidf = v.fit_transform(corpus)
    st.session_state.vectorizer = v
    st.session_state.tfidf = tfidf

    vec = st.session_state.vectorizer.transform([q])
    sims = linear_kernel(vec, st.session_state.tfidf).flatten()
    idxc =sims.argsort()[::-1][:top_k]
    rows = st.session_state.faq_df.iloc[idxc].copy()
    rows['score']=sims[idxc]

    best_ans = None
    best_score = float(rows['score'].iloc[0]) if len(rows) else 0.0
    with result_placeholder.container():
        if best_score >= c:
            best_ans = rows['answer'].iloc[0]
            if best_ans:
                st.markdown(
                """
                <div style="display: flex; justify-content: space-between;">
                    <span>æœ€ä½³æŸ¥è©¢çµæœï¼š</span>
                    <span>æŒ‰æ­£ä¸‹æ–¹åœ–ç¤ºå¯è¤‡è£½å›ç­”</span>
                </div>
                """,
                unsafe_allow_html=True
            )
                st.code(best_ans, language='text')
                st.session_state.status_label = "ç‹€æ…‹ï¼šæŸ¥è©¢å®Œæˆ"
                st.session_state.status_state = "complete"
                status_box.update(label=st.session_state.status_label, state=st.session_state.status_state)
        else:
            st.info('æ‰¾ä¸åˆ°é©åˆçš„å›æ‡‰ã€‚')
            st.session_state.status_label = "ç‹€æ…‹ï¼šæŸ¥è©¢å®Œæˆï¼Œä½†ç„¡åˆé©å›æ‡‰"
            st.session_state.status_state = "complete"
            status_box.update(label=st.session_state.status_label, state=st.session_state.status_state)
        st.write("å€™é¸æŸ¥è©¢çµæœï¼š")
        st.dataframe(rows[['question', 'answer', 'score']], use_container_width=True)
